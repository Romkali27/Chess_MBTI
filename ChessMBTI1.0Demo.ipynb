{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "365f5172-feda-44a6-a7d5-088f6fbab91f",
   "metadata": {},
   "source": [
    "# Welcome to **Chess MBTI** for lichess.org! \n",
    "### This project is designed for curious chess players who want to learn about their playing style and improve their results.\n",
    "### The main concept behind Chess MBTI is based on Myers-Briggs Type Indicator, or MBTI for short.\n",
    "### Players will be evaluated on 4 different categories:\n",
    "##### - Decision Making: U (Ultra-Calculator) / I (Instinctive) – describes the thought process behind player’s moves.\n",
    "##### - Position Handling: G (Grinder) / H (Hunter) – does the player capitalize on small, positional gains, or pounces on initiative?\n",
    "##### - Opening Approach: T (Theoretical) / N (Nonconformist) – does the player go with the flow in the opening, or studies them diligently?\n",
    "##### - Playing Style: L (Level-Headed) / V (Volatile) – mostly shaped by player’s middlegame approach: goes for calm/chaotic positions?\n",
    "### After evaluating the playing style, opening recommendations, middlegame advice and best personal MBTI matchups will be provided!\n",
    "### This notebook will cover all theoretical and technical details, let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df25e608-edcf-481d-9534-617acc1235fc",
   "metadata": {},
   "source": [
    "## First of all, it's crucial to install all of the necessary packages and libraries.\n",
    "### Let's look at them and their role one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42ee7c-1b01-482f-b8a7-2559b8974ee1",
   "metadata": {},
   "source": [
    "##### 1. Berserk - allows to connect with Lichess API to import the games for analysis.\n",
    "##### 2. Pandas - provides functionality to complete statistical and exploratory analysis.\n",
    "##### 3. Matplotlib - will be used for visualization.\n",
    "##### 4. Scikit-learn - a crucial machine learning library that will be used for model building.\n",
    "##### 5. Numpy - a popular Python library that will be used for mathematical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfdda7d3-d06c-4f03-bdf1-801892accc85",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: berserk in c:\\users\\romkali\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: deprecated<2.0.0,>=1.2.14 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from berserk) (1.2.18)\n",
      "Requirement already satisfied: ndjson<0.4.0,>=0.3.1 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from berserk) (0.3.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from berserk) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.2 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from berserk) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.1 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from berserk) (4.12.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from deprecated<2.0.0,>=1.2.14->berserk) (1.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.8.2->berserk) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.28.2->berserk) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.28.2->berserk) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.28.2->berserk) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.28.2->berserk) (2025.1.31)\n",
      "Requirement already satisfied: pandas in c:\\users\\romkali\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\romkali\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\romkali\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\romkali\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from xgboost) (1.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\romkali\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\romkali\\anaconda3\\lib\\site-packages (from dotenv) (0.21.0)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Installing collected packages: dotenv\n",
      "Successfully installed dotenv-0.9.9\n"
     ]
    }
   ],
   "source": [
    "!pip install berserk\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install xgboost\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2a054e-eb76-4876-a856-1c1620f81ca3",
   "metadata": {},
   "source": [
    "### Now let's import the newly installed libraries and functionalities to enable them for usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7180f461-dde1-4d0c-9f5b-c17d4f3e5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import berserk\n",
    "import base64\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import xgboost\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3df5e1-af70-4cb6-8059-7ff828c4be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from results import result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653de260-9838-4890-bc46-80dc3156b7a4",
   "metadata": {},
   "source": [
    "### Final step of the preparation - obtaining the token to interact with lichess API.\n",
    "### This token enables us to start the API session, which signals the start of your activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20dadf35-b47f-41fb-a400-d1a81e2d5978",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = berserk.TokenSession('')\n",
    "client = berserk.Client(session=session)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd49ab9-a1e1-4f87-98af-1a17ed5cbb2b",
   "metadata": {},
   "source": [
    "## Now we are free to begin the more exciting part - **data importing and analysis**.\n",
    "### To start, we initialize the rating threshold and type threshold dictionaries.\n",
    "### What's happening here is that we divide the players into rating groups using the rating threshold dictionary.\n",
    "### This allows us to more fairly evaluate the players based on their rating stage and the thresholds from type threshold dictionary.\n",
    "### At the moment they might seem like some random numbers, but they will be explained later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e43a39a-77f6-4734-bff4-9282d14b3447",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rating_thresholds = {1200: 'beginner', 1500: 'amateur', 1800: 'upper-intermidiate', 2150: 'advanced', 100000: 'specialist'}\n",
    "type_thresholds = {\n",
    "0 : {'beginner': [[5,6.5], 4.75], 'amateur': [[5.5, 7], 5], 'upper-intermidiate': [[6, 7.5], 5.5], 'advanced': [[5.5,7.5],5],'specialist': [[5, 6.5], 4.75]},\n",
    "1 : {'beginner': [[0.65, 0.825], 38], 'amateur': [[0.55, 0.7], 41], 'upper-intermidiate': [[0.45, 0.575], 44], 'advanced': [[0.375, 0.475],47],'specialist': [[0.335, 0.425], 50]},\n",
    "2 : {'beginner': [[0.45, 0.55], 5], 'amateur': [[0.35,0.45], 6], 'upper-intermidiate': [[0.25, 0.35], 6.5], 'advanced': [[0.175,0.275],7],'specialist': [[0.125, 0.2], 7.5]},\n",
    "3 : {'beginner': [[0.75, 1.15], 0.4] , 'amateur': [[0.7, 1], 0.35], 'upper-intermidiate': [[0.65, 0.9], 0.3], 'advanced': [[0.6, 0.8], 0.25],'specialist': [[0.58, 0.75], 0.22]}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101cf8a9-d503-43f2-a268-9388f5148481",
   "metadata": {},
   "source": [
    "### Now let's dive into the main data importing function, which I called get_data.\n",
    "### Every detail of the code below will be explain in the comment section, signified by ## symbols.\n",
    "### Feel free to take your time and inspect the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872d165a-f13c-4166-9b98-525f07198be8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(nickname): ## Initialize the function. The only parameter here is the nickname of the player.\n",
    "    raw_data = client.games.export_by_player(nickname, max=100,evals=True, clocks=True,opening=True, perf_type=['blitz','rapid'], analysed=True, tags=False)\n",
    "    ## In the line above, we use the client instance, established using our token to import games of a player.\n",
    "    ## The parameters of the function in brackets specify the details of what data should be imported.\n",
    "    ## In this case, the data is 100 most recent analyzed games with evaluations, time usage and opening data from blitz and rapid time control.\n",
    "    games = list(raw_data)\n",
    "    ## Notice that the imported data is called raw_data. The reason is that you have to change it's type for it to be analyzable.\n",
    "    ## We do this by organizing it in a list, which will contain each game in an order - from most to least recent.\n",
    "    if len(games)<10:\n",
    "        print('Not enough analyzed games yet!')\n",
    "        return None, None, None\n",
    "    ## Now that the data is readable, we ensure that there is enough material to work with.\n",
    "    ## To do this, we check the length of the list, which is the amount of games imported.\n",
    "    ## If there are less than 10 games, we print the according message and stop the function.\n",
    "    opening_swing_list = [] ## In the lines preceeding the for cycle, we are initializing data containers for us to store the game data in.\n",
    "    blunder_score_list = []\n",
    "    no_tp_time_usage_means = []\n",
    "    no_tp_time_usage_stds = []\n",
    "    no_tp_eval_swing_stds = []\n",
    "    no_tp_eval_swing_means = []\n",
    "    game_cnt = 0\n",
    "    color = ''\n",
    "    debut_depth_list = []\n",
    "    eval_swing_means = []\n",
    "    eval_swing_stds = []\n",
    "    normalized_time_usage_means = []\n",
    "    normalized_time_usage_stds = []\n",
    "    opening_eval_swings = []\n",
    "    moves_per_game = []\n",
    "    moves_btp_list=[]\n",
    "    mean=0\n",
    "    \n",
    "    for game in games: ## Now we begin to access each game of the list for the data.\n",
    "        moves_btp = 0 ## Once again, starting with initializing the data containers for future use.\n",
    "        no_tp_eval_swing_list=[]\n",
    "        no_tp_time_usage_list = []\n",
    "        increment = int(game['clock']['increment'])\n",
    "        time_list = []\n",
    "        eval_swing_list = []\n",
    "        time_std = 0\n",
    "        eval_swing_mean = 0\n",
    "        eval_swing_std = 0\n",
    "        plies = len(game['moves'].split(' '))\n",
    "        moves = plies//2\n",
    "        game_cnt+=1\n",
    "        moves_per_game.append(moves)\n",
    "        if 'opening' in game.keys(): ## To avoid rare occasions where lichess doesn't recognize the opening, we will append 1 as length of an opening.\n",
    "            debut_depth_list.append(game['opening']['ply'])\n",
    "        else:\n",
    "            debut_depth_list.append(1)\n",
    "            \n",
    "        if 'user' in game['players']['white'].keys() and 'user' in game['players']['black'].keys(): ## Now we identify the player's piece color.\n",
    "            if game['players']['white']['user']['name'].lower() == nickname.lower():\n",
    "                color = 'w'\n",
    "                blunder_points = game['players']['white']['analysis']['inaccuracy']/2 + game['players']['white']['analysis']['mistake']*1.5 + game['players']['white']['analysis']['blunder']*3\n",
    "                blunder_score = blunder_points/moves ## (Blunder score = Inaccuracies * 0.5 + Mistakes * 1.5 + Blunders * 3) / Move amount\n",
    "                blunder_score_list.append(round(blunder_score,2)) ## At the same time we can calculate the blunder score, which tells the amount of size of mistake.\n",
    "                mean+=game['players']['white']['rating'] ## Appending the actual rating of a player to identify his rating stage.\n",
    "            else:\n",
    "                color = 'b'\n",
    "                blunder_points = game['players']['black']['analysis']['inaccuracy'] + game['players']['black']['analysis']['mistake']*2 + game['players']['black']['analysis']['blunder']*3\n",
    "                blunder_score = blunder_points/moves\n",
    "                blunder_score_list.append(round(blunder_score,2))\n",
    "                mean+=game['players']['black']['rating']\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "            \n",
    "        for i in range(len(game['analysis'])):\n",
    "            if type(game['analysis'][i].get('eval')) != int:\n",
    "                game['analysis'][i]['mate']=1500 \n",
    "                ## To evaluate the evaluation swing, we have to keep them consistent, so when there is a mate in position,\n",
    "                ## we evaluate it as a 1500 centipawn advantage or disadvantage to avoid miscalculations.\n",
    "                \n",
    "    \n",
    "        evals = [i.get('eval') if type(i.get('eval')) == int else i.get('mate') for i in game['analysis']]\n",
    "        ## Generate a full evaluation list for the game to analyze the swings.\n",
    "\n",
    "        if plies > len(evals):\n",
    "            pass\n",
    "        else:\n",
    "            for i in range(2, plies-2):\n",
    "                if plies > 0:\n",
    "                    j = i-1\n",
    "                    if color == 'w':\n",
    "                        if i % 2 == 0:\n",
    "                            move_time = ((int(game['clocks'][i]) - int(game['clocks'][i+2]))/100+increment)\n",
    "                            time_list.append(round(move_time, 2))\n",
    "                            eval_swing_list.append(abs(evals[i]-evals[j]))\n",
    "                            if 'opening' not in game.keys():\n",
    "                                if int(game['clocks'][i+2]) > 0.2*int(game['clocks'][0]) and i//2+1:\n",
    "                                    no_tp_eval_swing_list.append((abs(evals[i]-evals[j])))\n",
    "                                    no_tp_time_usage_list.append(round(move_time, 2))\n",
    "                                    moves_btp +=1\n",
    "        ## Now we start to fill our data containers with statistical data like moves before time trouble amount, time usage and evaluation swings. \n",
    "        ## Notice that there are separate 'no_tp' versions of lists, which means 'no time pressure'. For the sake of this project, TT = >20% of time.\n",
    "                            else:\n",
    "                                if int(game['clocks'][i+2]) > 0.2*int(game['clocks'][0]) and i//2+1 > game['opening']['ply']//2:\n",
    "                                    no_tp_eval_swing_list.append((abs(evals[i]-evals[j])))\n",
    "                                    no_tp_time_usage_list.append(round(move_time, 2))\n",
    "                                    moves_btp +=1     \n",
    "                    else:\n",
    "                        if i % 2 == 1:\n",
    "                            move_time = ((int(game['clocks'][i]) - int(game['clocks'][i+2]))/100+increment)\n",
    "                            time_list.append(round(move_time, 2))\n",
    "                            eval_swing_list.append(abs(evals[i]-evals[j]))\n",
    "                            if 'opening' not in game.keys():\n",
    "                                if int(game['clocks'][i+2]) > 0.2*int(game['clocks'][0]) and i//2+1:\n",
    "                                    no_tp_eval_swing_list.append((abs(evals[i]-evals[j])))\n",
    "                                    no_tp_time_usage_list.append(round(move_time, 2))\n",
    "                                    moves_btp +=1\n",
    "                            else:\n",
    "                                if int(game['clocks'][i+2]) > 0.2*int(game['clocks'][0]) and i//2+1 > game['opening']['ply']//2:\n",
    "                                    no_tp_eval_swing_list.append((abs(evals[i]-evals[j])))\n",
    "                                    no_tp_time_usage_list.append(round(move_time, 2))\n",
    "                                    moves_btp +=1\n",
    "    \n",
    "        no_tp_eval_swing_srs = pd.Series(no_tp_eval_swing_list)/100\n",
    "        nrm_no_tp_time_usage_srs = pd.Series(no_tp_time_usage_list)/(game['clock']['initial']+increment*moves)*100\n",
    "        opening_swing_list.append(round((sum(eval_swing_list[0:10])/1000), 2) if moves>11 else round((sum(eval_swing_list)/1000), 2))\n",
    "        nrm_time_list_srs = pd.Series(time_list)/(game['clock']['initial']+increment*moves)*100\n",
    "        eval_swing_srs = pd.Series(eval_swing_list)/100\n",
    "        debut_depth_srs = pd.Series(debut_depth_list)\n",
    "        moves_per_game_srs = pd.Series(moves_per_game)\n",
    "        no_tp_time_usage_srs=pd.Series(no_tp_time_usage_list)\n",
    "        moves_btp_list.append(moves_btp)\n",
    "        ## In the code block above, we convert our Python lists to Pandas objects called Series.\n",
    "        ## The reason is very simple - we can take statistical measures like mean and std from them in just one method.\n",
    "\n",
    "        no_tp_eval_swing_means.append(round(no_tp_eval_swing_srs.mean(), 2))\n",
    "        no_tp_eval_swing_stds.append(round(no_tp_eval_swing_srs.std(), 2))\n",
    "        eval_swing_means.append(round(eval_swing_srs.mean(),2))\n",
    "        eval_swing_stds.append(round(eval_swing_srs.std(),2))\n",
    "        normalized_time_usage_means.append(round(nrm_time_list_srs.mean(),2))\n",
    "        normalized_time_usage_stds.append(round(nrm_time_list_srs.std(),2))\n",
    "        no_tp_time_usage_means.append(round(no_tp_time_usage_srs.mean(),2))\n",
    "        no_tp_time_usage_stds.append(round(no_tp_time_usage_srs.std(),2))\n",
    "\n",
    "        ## And now we do exactly that to populate our end data containers, which will be the analysis data sources.\n",
    "    \n",
    "    blunder_score_srs = pd.Series(blunder_score_list)\n",
    "    no_tp_eval_swing_stds_pds = pd.Series(no_tp_eval_swing_stds)\n",
    "    no_tp_eval_swing_means_pds = pd.Series(no_tp_eval_swing_means)\n",
    "    opening_swing_list_pds = pd.Series(opening_swing_list)\n",
    "    debut_depth_list_pds = pd.Series(debut_depth_list)\n",
    "    eval_swing_means_pds = pd.Series(eval_swing_means)\n",
    "    eval_swing_stds_pds = pd.Series(eval_swing_stds)\n",
    "    normalized_time_usage_means_pds = pd.Series(normalized_time_usage_means)\n",
    "    normalized_time_usage_stds_pds = pd.Series(normalized_time_usage_means)\n",
    "    moves_per_game_pds = pd.Series(moves_per_game)\n",
    "    no_tp_time_usage_means_pds = pd.Series(no_tp_time_usage_means)\n",
    "    no_tp_time_usage_stds_pds = pd.Series(no_tp_time_usage_stds)\n",
    "    moves_btp_pds=pd.Series(moves_btp_list)\n",
    "    ## All that's left to do is to convert these end data containers into Series themselves.\n",
    "\n",
    "\n",
    "\n",
    "    result_type = '' ## Initializing a text object, which will contain the final rating type.\n",
    "    mean//=game_cnt \n",
    "    for key in list(rating_thresholds.keys()):\n",
    "        if mean < key:\n",
    "            stage = rating_thresholds[key]\n",
    "            break\n",
    "    ## Determine the rating stage by taking the total ratings, dividing them by the amount of games and checking, which stage fits the result.\n",
    "\n",
    "    type_criterions = {\n",
    "                0 : [no_tp_time_usage_stds_pds.mean(), no_tp_time_usage_means_pds.mean(),'IU'],\n",
    "                1 : [no_tp_eval_swing_means_pds.mean(), moves_per_game_pds.quantile(q=0.75),'GH'],\n",
    "                2 : [opening_swing_list_pds.mean(), debut_depth_list_pds.mean(),'TN'],\n",
    "                3: [no_tp_eval_swing_stds_pds.mean(), blunder_score_srs.mean(), 'LV']\n",
    "                }\n",
    "    ## The dictionary above shows which criteria will be used to conduct the primary analysis and to determine the result MBTI.\n",
    "    ## For U/I - Time usage STD/Time usage mean\n",
    "    ## For G/H - Evaluation swing mean, 75% quantile of move amount\n",
    "    ## For T/N - Evaluation swing in the opening/Length of opening theory mean\n",
    "    ## For L/V - Evaluation swing STD/Blunder score mean\n",
    "    \n",
    "\n",
    "    for i in range(len(type_thresholds)):\n",
    "        criteria_min_value = type_thresholds[i][stage][0][0]\n",
    "        criteria_max_value = type_thresholds[i][stage][0][1]\n",
    "        criteria_second_value = type_thresholds[i][stage][1]\n",
    "        user_first_criteria_value = type_criterions[i][0]\n",
    "        user_second_criteria_value = type_criterions[i][1]     \n",
    "        if i not in [1,2]:\n",
    "            if criteria_min_value >= user_first_criteria_value:\n",
    "                result_type+=(type_criterions[i][2][0])\n",
    "            elif criteria_max_value <= user_first_criteria_value:\n",
    "                result_type+=type_criterions[i][2][1]\n",
    "            else:\n",
    "                if criteria_second_value > user_second_criteria_value:\n",
    "                    result_type+=(type_criterions[i][2][0])\n",
    "                else:\n",
    "                    result_type+=(type_criterions[i][2][1])\n",
    "        else:\n",
    "            if criteria_min_value > user_first_criteria_value:\n",
    "                result_type+=(type_criterions[i][2][0])\n",
    "            elif criteria_max_value < user_first_criteria_value:\n",
    "                result_type+=type_criterions[i][2][1]\n",
    "            else:\n",
    "                if criteria_second_value > user_second_criteria_value:\n",
    "                    result_type+=(type_criterions[i][2][1])\n",
    "                else:\n",
    "                    result_type+=(type_criterions[i][2][0])\n",
    "        ## Now we enter the type calculation process. The initial techinque is as follows:\n",
    "        ## Check the first criteria user value and compare it with the smaller and the larger threshold.\n",
    "        ## If the value is less than the smaller threshold or larger than the bigger one, the letter is assigned.\n",
    "        ## If the value is between them, compare the second value with the threshold and assign the letter.\n",
    "\n",
    "    \n",
    "    data=blunder_score_srs.mean(),opening_swing_list_pds.mean(),no_tp_eval_swing_stds_pds.mean(), no_tp_eval_swing_means_pds.mean(),debut_depth_list_pds.mean(),eval_swing_means_pds.mean(),eval_swing_stds_pds.mean(),normalized_time_usage_means_pds.mean(),normalized_time_usage_stds_pds.mean(),moves_per_game_pds.quantile(q=0.75),no_tp_time_usage_means_pds.mean(),no_tp_time_usage_stds_pds.mean(),moves_btp_pds.mean()\n",
    "    X = pd.DataFrame(data=[data], columns=['Blunder scores','Eval swings (first 10 moves)','Eval swings std (middlegame)', 'Eval swings mean (middlegame)','Opening depth','Mean eval swings', 'Eval swing std', 'Mean time usage per move (%)', 'Time usage std per move (%)', 'Moves per game', 'Mean time usage per move (%, middlegame)', 'Time usage std per move (%, middlegame)', 'Moves before time pressure'])\n",
    "    return X, result_type, stage\n",
    "    ## Lastly, return the analyzed data along with the calculated MBTI and rating stage. They will be used later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a27e9cc-c0b4-459f-980d-0124ba750d95",
   "metadata": {},
   "source": [
    "### In order to create a dataset for model training, we also create a second version of data importing function.\n",
    "### This version will treat each game as a separate data entry to increase the amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a57805c-ac30-477c-80e9-5ce7491f1eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_2(nickname): \n",
    "    ## Now let's quickly look at the second version of the data collection function. \n",
    "    ## It was created to create training and testing datasets for model building, which will be shown later.\n",
    "    ## In this function we will only look at the details that differ from the original function.\n",
    "    raw_data = client.games.export_by_player(nickname, max=200,evals=True, clocks=True,opening=True, perf_type=['blitz','rapid'], analysed=True, tags=False)\n",
    "    games = list(raw_data)\n",
    "    if len(games)<50:\n",
    "        return None\n",
    "        quit()\n",
    "    X = pd.DataFrame(columns=['Blunder scores','Eval swings (first 10 moves)','Eval swings std (middlegame)', 'Eval swings mean (middlegame)','Opening depth','Mean eval swings', 'Eval swing std', 'Mean time usage per move (%)', 'Time usage std per move (%)', 'Moves per game', 'Mean time usage per move (%, middlegame)', 'Time usage std per move (%, middlegame)', 'Moves before time pressure', 'Type 1','Type 2','Type 3','Type 4'])\n",
    "    \n",
    "    for game in games:\n",
    "        if 'opening' not in game.keys():\n",
    "            continue\n",
    "        else: \n",
    "            opening_swing_list = []\n",
    "            blunder_score_list = []\n",
    "            no_tp_time_usage_means = []\n",
    "            no_tp_time_usage_stds = []\n",
    "            no_tp_eval_swing_stds = []\n",
    "            no_tp_eval_swing_means = []\n",
    "            mean = 0\n",
    "            game_cnt = 0\n",
    "            stage = ''\n",
    "            color = ''\n",
    "            debut_depth_list = []\n",
    "            eval_swing_means = []\n",
    "            eval_swing_stds = []\n",
    "            normalized_time_usage_means = []\n",
    "            normalized_time_usage_stds = []\n",
    "            opening_eval_swings = []\n",
    "            moves_per_game = []\n",
    "            moves_btp_list=[]\n",
    "            moves_btp = 0\n",
    "            no_tp_eval_swing_list=[]\n",
    "            no_tp_time_usage_list = []\n",
    "            game_cnt+=1\n",
    "            increment = int(game['clock']['increment'])\n",
    "            time_list = []\n",
    "            eval_swing_list = []\n",
    "            time_std = 0\n",
    "            eval_swing_mean = 0\n",
    "            eval_swing_std = 0\n",
    "            plies = len(game['moves'].split(' '))\n",
    "            moves = plies//2\n",
    "            moves_per_game.append(moves)\n",
    "            if 'opening' in game.keys():\n",
    "                debut_depth_list.append(game['opening']['ply'])\n",
    "            else:\n",
    "                debut_depth_list.append(1)\n",
    "                \n",
    "            if 'user' in game['players']['white'].keys() and 'user' in game['players']['black'].keys():\n",
    "                if game['players']['white']['user']['name'].lower() == nickname.lower():\n",
    "                    mean += game['players']['white']['rating']\n",
    "                    color = 'w'\n",
    "                    blunder_points = game['players']['white']['analysis']['inaccuracy']/2 + game['players']['white']['analysis']['mistake']*1.5 + game['players']['white']['analysis']['blunder']*3\n",
    "                    blunder_score = blunder_points/moves \n",
    "                    blunder_score_list.append(round(blunder_score,2))\n",
    "                else:\n",
    "                    mean += game['players']['white']['rating'] \n",
    "                    color = 'b'\n",
    "                    blunder_points = game['players']['black']['analysis']['inaccuracy'] + game['players']['black']['analysis']['mistake']*2 + game['players']['black']['analysis']['blunder']*3\n",
    "                    blunder_score = blunder_points/moves\n",
    "                    blunder_score_list.append(round(blunder_score,2))\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "                \n",
    "            for i in range(len(game['analysis'])):\n",
    "                if type(game['analysis'][i].get('eval')) != int:\n",
    "                    game['analysis'][i]['mate']=1500\n",
    "        \n",
    "            evals = [i.get('eval') if type(i.get('eval')) == int else i.get('mate') for i in game['analysis']]\n",
    "    \n",
    "            if plies > len(evals):\n",
    "                pass\n",
    "            else:\n",
    "                for i in range(2, plies-2):\n",
    "                    if plies > 0:\n",
    "                        j = i-1\n",
    "                        if color == 'w':\n",
    "                            if i % 2 == 0:\n",
    "                                move_time = ((int(game['clocks'][i]) - int(game['clocks'][i+2]))/100+increment)\n",
    "                                time_list.append(round(move_time, 2))\n",
    "                                eval_swing_list.append(abs(evals[i]-evals[j]))\n",
    "                                if 'opening' not in game.keys():\n",
    "                                    if int(game['clocks'][i+2]) > 0.2*int(game['clocks'][0]) and i//2+1:\n",
    "                                        no_tp_eval_swing_list.append((abs(evals[i]-evals[j])))\n",
    "                                        no_tp_time_usage_list.append(round(move_time, 2))\n",
    "                                        moves_btp +=1\n",
    "                                else:\n",
    "                                    if int(game['clocks'][i+2]) > 0.2*int(game['clocks'][0]) and i//2+1 > game['opening']['ply']//2:\n",
    "                                        no_tp_eval_swing_list.append((abs(evals[i]-evals[j])))\n",
    "                                        no_tp_time_usage_list.append(round(move_time, 2))\n",
    "                                        moves_btp +=1     \n",
    "                        else:\n",
    "                            if i % 2 == 1:\n",
    "                                move_time = ((int(game['clocks'][i]) - int(game['clocks'][i+2]))/100+increment)\n",
    "                                time_list.append(round(move_time, 2))\n",
    "                                eval_swing_list.append(abs(evals[i]-evals[j]))\n",
    "                                if 'opening' not in game.keys():\n",
    "                                    if int(game['clocks'][i+2]) > 0.2*int(game['clocks'][0]) and i//2+1:\n",
    "                                        no_tp_eval_swing_list.append((abs(evals[i]-evals[j])))\n",
    "                                        no_tp_time_usage_list.append(round(move_time, 2))\n",
    "                                        moves_btp +=1\n",
    "                                else:\n",
    "                                    if int(game['clocks'][i+2]) > 0.2*int(game['clocks'][0]) and i//2+1 > game['opening']['ply']//2:\n",
    "                                        no_tp_eval_swing_list.append((abs(evals[i]-evals[j])))\n",
    "                                        no_tp_time_usage_list.append(round(move_time, 2))\n",
    "                                        moves_btp +=1\n",
    "        \n",
    "            no_tp_eval_swing_srs = pd.Series(no_tp_eval_swing_list)/100\n",
    "            nrm_no_tp_time_usage_srs = pd.Series(no_tp_time_usage_list)/(game['clock']['initial']+increment*moves)*100\n",
    "            opening_swing_list.append(round((sum(eval_swing_list[0:10])/1000), 2) if moves>11 else round((sum(eval_swing_list)/1000), 2))\n",
    "            nrm_time_list_srs = pd.Series(time_list)/(game['clock']['initial']+increment*moves)*100\n",
    "            eval_swing_srs = pd.Series(eval_swing_list)/100\n",
    "            debut_depth_srs = pd.Series(debut_depth_list)\n",
    "            moves_per_game_srs = pd.Series(moves_per_game)\n",
    "            no_tp_time_usage_srs=pd.Series(no_tp_time_usage_list)\n",
    "            moves_btp_list.append(moves_btp)\n",
    "        \n",
    "            no_tp_eval_swing_means.append(round(no_tp_eval_swing_srs.mean(), 2))\n",
    "            no_tp_eval_swing_stds.append(round(no_tp_eval_swing_srs.std(), 2))\n",
    "            eval_swing_means.append(round(eval_swing_srs.mean(),2))\n",
    "            eval_swing_stds.append(round(eval_swing_srs.std(),2))\n",
    "            normalized_time_usage_means.append(round(nrm_time_list_srs.mean(),2))\n",
    "            normalized_time_usage_stds.append(round(nrm_time_list_srs.std(),2))\n",
    "            no_tp_time_usage_means.append(round(no_tp_time_usage_srs.mean(),2))\n",
    "            no_tp_time_usage_stds.append(round(no_tp_time_usage_srs.std(),2))\n",
    "\n",
    "\n",
    "            blunder_score_srs = pd.Series(blunder_score_list)\n",
    "            no_tp_eval_swing_stds_pds = pd.Series(no_tp_eval_swing_stds)\n",
    "            no_tp_eval_swing_means_pds = pd.Series(no_tp_eval_swing_means)\n",
    "            opening_swing_list_pds = pd.Series(opening_swing_list)\n",
    "            debut_depth_list_pds = pd.Series(debut_depth_list)\n",
    "            eval_swing_means_pds = pd.Series(eval_swing_means)\n",
    "            eval_swing_stds_pds = pd.Series(eval_swing_stds)\n",
    "            normalized_time_usage_means_pds = pd.Series(normalized_time_usage_means)\n",
    "            normalized_time_usage_stds_pds = pd.Series(normalized_time_usage_means)\n",
    "            moves_per_game_pds = pd.Series(moves_per_game)\n",
    "            no_tp_time_usage_means_pds = pd.Series(no_tp_time_usage_means)\n",
    "            no_tp_time_usage_stds_pds = pd.Series(no_tp_time_usage_stds)\n",
    "            moves_btp_pds=pd.Series(moves_btp_list)\n",
    "\n",
    "            ## As some of you might have noticed, in the first version the end data containers were created after all the games were analyzed.\n",
    "            ## In this case, since we want to the data from all games, we moved it to be a process for each game.\n",
    "    \n",
    "            result_type = ''\n",
    "            for key in list(rating_thresholds.keys()):\n",
    "                if mean < key:\n",
    "                    stage = rating_thresholds[key]\n",
    "                    break\n",
    "        \n",
    "            type_criterions = {\n",
    "                            0 : [no_tp_time_usage_stds_pds.mean(), no_tp_time_usage_means_pds.mean(),'IU'], #Let the middle interval be bigger\n",
    "                            1 : [no_tp_eval_swing_means_pds.mean(), moves/4*3,'GH'], #Think about implementing quantiles here\n",
    "                            2 : [opening_swing_list_pds.mean(), debut_depth_list_pds.mean(),'TN'],\n",
    "                            3: [no_tp_eval_swing_stds_pds.mean(), blunder_score_srs.mean(), 'LV']\n",
    "                            }\n",
    "                                \n",
    "            for i in range(len(type_thresholds)):\n",
    "                criteria_min_value = type_thresholds[i][stage][0][0]\n",
    "                criteria_max_value = type_thresholds[i][stage][0][1]\n",
    "                criteria_second_value = type_thresholds[i][stage][1]\n",
    "                user_first_criteria_value = type_criterions[i][0]\n",
    "                user_second_criteria_value = type_criterions[i][1]     \n",
    "                if i not in [1,2]:\n",
    "                    if criteria_min_value >= user_first_criteria_value:\n",
    "                        result_type+=(type_criterions[i][2][0])\n",
    "                    elif criteria_max_value <= user_first_criteria_value:\n",
    "                        result_type+=type_criterions[i][2][1]\n",
    "                    else:\n",
    "                        if criteria_second_value > user_second_criteria_value:\n",
    "                            result_type+=(type_criterions[i][2][0])\n",
    "                        else:\n",
    "                            result_type+=(type_criterions[i][2][1])\n",
    "                else:\n",
    "                    if criteria_min_value > user_first_criteria_value:\n",
    "                        result_type+=(type_criterions[i][2][0])\n",
    "                    elif criteria_max_value < user_first_criteria_value:\n",
    "                        result_type+=type_criterions[i][2][1]\n",
    "                    else:\n",
    "                        if criteria_second_value > user_second_criteria_value:\n",
    "                            result_type+=(type_criterions[i][2][1])\n",
    "                        else:\n",
    "                            result_type+=(type_criterions[i][2][0])\n",
    "            ## Now we have a separate type calculated and the data extracted for each game.\n",
    "\n",
    "            dataset=blunder_score,pd.Series(opening_swing_list).mean(),pd.Series(no_tp_eval_swing_list).std()/100, pd.Series(no_tp_eval_swing_list).mean()/100,game['opening']['ply'],pd.Series(eval_swing_list).mean()/100,pd.Series(eval_swing_list).std()/100,nrm_time_list_srs.mean(),nrm_time_list_srs.std(),moves/4*3,pd.Series(no_tp_time_usage_list).mean(),pd.Series(no_tp_time_usage_list).std(),moves_btp,result_type[0],result_type[1],result_type[2],result_type[3]\n",
    "            data=pd.DataFrame(data=[dataset],columns=['Blunder scores','Eval swings (first 10 moves)','Eval swings std (middlegame)', 'Eval swings mean (middlegame)','Opening depth','Mean eval swings', 'Eval swing std', 'Mean time usage per move (%)', 'Time usage std per move (%)', 'Moves per game', 'Mean time usage per move (%, middlegame)', 'Time usage std per move (%, middlegame)', 'Moves before time pressure', 'Type 1','Type 2','Type 3','Type 4'])\n",
    "            X=pd.concat([X, data], axis=0)\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e544a-71df-4e7b-b7e3-c1856e3d6c93",
   "metadata": {},
   "source": [
    "## Run the cell below to load the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1a47c3a-8782-4d14-9b03-3dd3ad3fab4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blunder scores</th>\n",
       "      <th>Eval swings (first 10 moves)</th>\n",
       "      <th>Eval swings std (middlegame)</th>\n",
       "      <th>Eval swings mean (middlegame)</th>\n",
       "      <th>Opening depth</th>\n",
       "      <th>Mean eval swings</th>\n",
       "      <th>Eval swing std</th>\n",
       "      <th>Mean time usage per move (%)</th>\n",
       "      <th>Time usage std per move (%)</th>\n",
       "      <th>Moves per game</th>\n",
       "      <th>Mean time usage per move (%, middlegame)</th>\n",
       "      <th>Time usage std per move (%, middlegame)</th>\n",
       "      <th>Moves before time pressure</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Type 3</th>\n",
       "      <th>Type 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.100428</td>\n",
       "      <td>0.463846</td>\n",
       "      <td>8</td>\n",
       "      <td>0.686250</td>\n",
       "      <td>1.720453</td>\n",
       "      <td>2.414489</td>\n",
       "      <td>3.943713</td>\n",
       "      <td>31.50</td>\n",
       "      <td>12.763077</td>\n",
       "      <td>15.616969</td>\n",
       "      <td>13</td>\n",
       "      <td>U</td>\n",
       "      <td>H</td>\n",
       "      <td>T</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.149512</td>\n",
       "      <td>0.110833</td>\n",
       "      <td>11</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.836770</td>\n",
       "      <td>3.749060</td>\n",
       "      <td>4.969120</td>\n",
       "      <td>20.25</td>\n",
       "      <td>10.433333</td>\n",
       "      <td>13.796841</td>\n",
       "      <td>12</td>\n",
       "      <td>U</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.287418</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>4</td>\n",
       "      <td>0.276750</td>\n",
       "      <td>0.341913</td>\n",
       "      <td>2.369697</td>\n",
       "      <td>4.046828</td>\n",
       "      <td>31.50</td>\n",
       "      <td>7.104762</td>\n",
       "      <td>9.371433</td>\n",
       "      <td>21</td>\n",
       "      <td>U</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.373689</td>\n",
       "      <td>0.229412</td>\n",
       "      <td>7</td>\n",
       "      <td>0.220385</td>\n",
       "      <td>0.553202</td>\n",
       "      <td>1.270775</td>\n",
       "      <td>3.233416</td>\n",
       "      <td>60.00</td>\n",
       "      <td>17.790588</td>\n",
       "      <td>27.254869</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.240599</td>\n",
       "      <td>0.230556</td>\n",
       "      <td>9</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.887032</td>\n",
       "      <td>3.436062</td>\n",
       "      <td>3.414080</td>\n",
       "      <td>19.50</td>\n",
       "      <td>16.293333</td>\n",
       "      <td>14.066444</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.26</td>\n",
       "      <td>4.636724</td>\n",
       "      <td>1.739333</td>\n",
       "      <td>2</td>\n",
       "      <td>1.739333</td>\n",
       "      <td>4.636724</td>\n",
       "      <td>2.080556</td>\n",
       "      <td>1.577572</td>\n",
       "      <td>24.00</td>\n",
       "      <td>6.241667</td>\n",
       "      <td>4.732715</td>\n",
       "      <td>30</td>\n",
       "      <td>I</td>\n",
       "      <td>H</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.557696</td>\n",
       "      <td>0.532500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.518623</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.541482</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.682500</td>\n",
       "      <td>1.196450</td>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.829474</td>\n",
       "      <td>2</td>\n",
       "      <td>0.636750</td>\n",
       "      <td>0.910386</td>\n",
       "      <td>2.423333</td>\n",
       "      <td>2.602794</td>\n",
       "      <td>31.50</td>\n",
       "      <td>12.058947</td>\n",
       "      <td>8.792758</td>\n",
       "      <td>19</td>\n",
       "      <td>U</td>\n",
       "      <td>H</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4392</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>1.54</td>\n",
       "      <td>2.247417</td>\n",
       "      <td>1.300476</td>\n",
       "      <td>2</td>\n",
       "      <td>1.832500</td>\n",
       "      <td>2.592671</td>\n",
       "      <td>2.665000</td>\n",
       "      <td>2.397740</td>\n",
       "      <td>28.50</td>\n",
       "      <td>10.601905</td>\n",
       "      <td>7.087549</td>\n",
       "      <td>21</td>\n",
       "      <td>U</td>\n",
       "      <td>H</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>1.187500</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.473276</td>\n",
       "      <td>1.996522</td>\n",
       "      <td>2</td>\n",
       "      <td>1.996522</td>\n",
       "      <td>2.473276</td>\n",
       "      <td>2.576522</td>\n",
       "      <td>1.926418</td>\n",
       "      <td>18.00</td>\n",
       "      <td>7.729565</td>\n",
       "      <td>5.779254</td>\n",
       "      <td>23</td>\n",
       "      <td>U</td>\n",
       "      <td>H</td>\n",
       "      <td>N</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3328 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Blunder scores  Eval swings (first 10 moves)  \\\n",
       "0           0.309524                          0.12   \n",
       "1           0.111111                          0.10   \n",
       "2           0.142857                          0.07   \n",
       "3           0.137500                          0.09   \n",
       "4           0.288462                          0.11   \n",
       "...              ...                           ...   \n",
       "4385        0.437500                          1.26   \n",
       "4386        0.250000                          0.22   \n",
       "4390        0.190476                          0.57   \n",
       "4392        0.789474                          1.54   \n",
       "4396        1.187500                          1.49   \n",
       "\n",
       "      Eval swings std (middlegame)  Eval swings mean (middlegame)  \\\n",
       "0                         1.100428                       0.463846   \n",
       "1                         0.149512                       0.110833   \n",
       "2                         0.287418                       0.219048   \n",
       "3                         0.373689                       0.229412   \n",
       "4                         0.240599                       0.230556   \n",
       "...                            ...                            ...   \n",
       "4385                      4.636724                       1.739333   \n",
       "4386                      0.557696                       0.532500   \n",
       "4390                      0.951872                       0.829474   \n",
       "4392                      2.247417                       1.300476   \n",
       "4396                      2.473276                       1.996522   \n",
       "\n",
       "      Opening depth  Mean eval swings  Eval swing std  \\\n",
       "0                 8          0.686250        1.720453   \n",
       "1                11          0.326000        0.836770   \n",
       "2                 4          0.276750        0.341913   \n",
       "3                 7          0.220385        0.553202   \n",
       "4                 9          0.430000        0.887032   \n",
       "...             ...               ...             ...   \n",
       "4385              2          1.739333        4.636724   \n",
       "4386              4          0.448000        0.518623   \n",
       "4390              2          0.636750        0.910386   \n",
       "4392              2          1.832500        2.592671   \n",
       "4396              2          1.996522        2.473276   \n",
       "\n",
       "      Mean time usage per move (%)  Time usage std per move (%)  \\\n",
       "0                         2.414489                     3.943713   \n",
       "1                         3.749060                     4.969120   \n",
       "2                         2.369697                     4.046828   \n",
       "3                         1.270775                     3.233416   \n",
       "4                         3.436062                     3.414080   \n",
       "...                            ...                          ...   \n",
       "4385                      2.080556                     1.577572   \n",
       "4386                      0.747333                     0.541482   \n",
       "4390                      2.423333                     2.602794   \n",
       "4392                      2.665000                     2.397740   \n",
       "4396                      2.576522                     1.926418   \n",
       "\n",
       "      Moves per game  Mean time usage per move (%, middlegame)  \\\n",
       "0              31.50                                 12.763077   \n",
       "1              20.25                                 10.433333   \n",
       "2              31.50                                  7.104762   \n",
       "3              60.00                                 17.790588   \n",
       "4              19.50                                 16.293333   \n",
       "...              ...                                       ...   \n",
       "4385           24.00                                  6.241667   \n",
       "4386            4.50                                  1.682500   \n",
       "4390           31.50                                 12.058947   \n",
       "4392           28.50                                 10.601905   \n",
       "4396           18.00                                  7.729565   \n",
       "\n",
       "      Time usage std per move (%, middlegame)  Moves before time pressure  \\\n",
       "0                                   15.616969                          13   \n",
       "1                                   13.796841                          12   \n",
       "2                                    9.371433                          21   \n",
       "3                                   27.254869                          17   \n",
       "4                                   14.066444                          18   \n",
       "...                                       ...                         ...   \n",
       "4385                                 4.732715                          30   \n",
       "4386                                 1.196450                           4   \n",
       "4390                                 8.792758                          19   \n",
       "4392                                 7.087549                          21   \n",
       "4396                                 5.779254                          23   \n",
       "\n",
       "     Type 1 Type 2 Type 3 Type 4  \n",
       "0         U      H      T      V  \n",
       "1         U      G      T      L  \n",
       "2         U      G      T      L  \n",
       "3         U      G      T      L  \n",
       "4         U      G      T      L  \n",
       "...     ...    ...    ...    ...  \n",
       "4385      I      H      N      V  \n",
       "4386      I      G      T      L  \n",
       "4390      U      H      N      L  \n",
       "4392      U      H      N      V  \n",
       "4396      U      H      N      V  \n",
       "\n",
       "[3328 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df=pd.read_csv('df1.csv') ## Just use this cell to use the resulting dataset.\n",
    "data_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data_df.dropna(inplace =True, axis=0) ## It's very important to clean your data before analysis. In this case, we do it by removing NaN entries.\n",
    "data_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105fb8a-6700-46e7-8863-958d219b683a",
   "metadata": {},
   "source": [
    "## Now we are ready to begin the analysis!\n",
    "### To do this, we separate our dataset into classifiers and main data.\n",
    "### Classifiers, in this case, are the MBTI letters, which are dependent on the main data.\n",
    "### Next we must scale the main data to improve the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79eb2a53-11cf-4dda-8576-076d603c0709",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = data_df[['Type 1', 'Type 2', 'Type 3', 'Type 4']] ## Extracting the MBTI letters as target variables to model for.\n",
    "data_df.drop(columns=['Type 1', 'Type 2', 'Type 3', 'Type 4'], inplace=True)\n",
    "data_df_scaled = StandardScaler().fit(data_df).transform(data_df) ## Scale the data to improve the accuracy.\n",
    "scaled_data = pd.DataFrame(data_df_scaled)\n",
    "scaled_data = pd.DataFrame(data_df_scaled,columns=['Blunder scores','Eval swings (first 10 moves)','Eval swings std (middlegame)', 'Eval swings mean (middlegame)','Opening depth','Mean eval swings', 'Eval swing std', 'Mean time usage per move (%)', 'Time usage std per move (%)', 'Moves per game', 'Mean time usage per move (%, middlegame)', 'Time usage std per move (%, middlegame)', 'Moves before time pressure'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df89d8b-20ba-466d-afb7-22be708f0040",
   "metadata": {},
   "source": [
    "### In machine learning, the dependent data is usually marked as Y, and the main data is marked as X.\n",
    "### That's exactly what we do here - scaled version of main data is X and the 4 different MBTI letters are marked Y1 to Y4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5d2b13c-91e2-4806-9efe-0dde8fd9fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_data ## Scaled data without target variables will be used to conduct the analysis.\n",
    "Y1 = classifiers['Type 1']\n",
    "Y2 = classifiers['Type 2']\n",
    "Y3 = classifiers['Type 3']\n",
    "Y4 = classifiers['Type 4']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed2710-982b-4036-8c1d-63daa4b490ae",
   "metadata": {},
   "source": [
    "## Now we have everything necessary to form the **training sets** and **testing sets** for our models to train on.\n",
    "### But what exactly is a training set and a training set?\n",
    "### In general, training set is passed into the model to determine the best parameters for the model in terms of the prediction accuracy.\n",
    "### Then, testing set is used to test these parameters and confirm or deny whether the parameters were well picked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a922ef-a2d6-41df-b0e6-1a023efd72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, Y1_train, Y1_test =train_test_split(X, Y1, test_size = 0.2, random_state = 42,stratify = Y1) \n",
    "X2_train, X2_test, Y2_train, Y2_test =train_test_split(X, Y2, test_size = 0.2, random_state = 42,stratify = Y2)\n",
    "X3_train, X3_test, Y3_train, Y3_test =train_test_split(X, Y3, test_size = 0.2, random_state = 42,stratify = Y3)\n",
    "X4_train, X4_test, Y4_train, Y4_test =train_test_split(X, Y4, test_size = 0.2, random_state = 42,stratify = Y4)\n",
    "## Divide the data into 80/20 proportions for model training.\n",
    "## 80% is the training set, 20% is the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909c47f-8e38-4165-8592-d1bfaa908445",
   "metadata": {},
   "source": [
    "## Last step of model building - let's run the cell below to initialize our Random Forest models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96404068-2aca-448f-844a-c237d9075f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_features=None)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_features=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1 = RandomForestClassifier(criterion='entropy', max_features=None, max_depth=7)\n",
    "M1.fit(X1_train, Y1_train)\n",
    "M2 = RandomForestClassifier(criterion='entropy', max_features=None, max_depth=None)\n",
    "M2.fit(X2_train, Y2_train)\n",
    "M3 = RandomForestClassifier(criterion='entropy', max_features=None, max_depth=None)\n",
    "M3.fit(X3_train, Y3_train)\n",
    "M4 = RandomForestClassifier(criterion='entropy', max_features=None, max_depth=None)\n",
    "M4.fit(X4_train, Y4_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a6998-b1a9-474d-a5d3-8b13cc06267c",
   "metadata": {},
   "source": [
    "## Alright, now we can finally move on to the best part - testing Chess MBTI on ourselves, or our friends if you will!\n",
    "## Simply input your nickname in the cell below, run the next cells and see the results for yourself.\n",
    "## Thank you in advance for sticking with me until the end, I appreciate it a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d24e905-6b8e-4d75-9016-c011eb92c3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type the nickname:  RomKali\n"
     ]
    }
   ],
   "source": [
    "nickname = str(input('Type the nickname: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59ebcc6b-a654-4263-94b9-14cc35ff5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, threshold_type, stage = get_data(nickname)\n",
    "type_dict = result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "838d9fbe-b432-4053-ac72-33ada4f47d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = StandardScaler()\n",
    "Scaler.fit(data_df)\n",
    "Scaler.transform(data_df)\n",
    "T_set = Scaler.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83743fff-ad78-461e-b91f-208dceb1087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: UGTL, threshold prediction: UGTL\n"
     ]
    }
   ],
   "source": [
    "result_type=''\n",
    "\n",
    "for i in [M1, M2, M3, M4]:\n",
    "    if len(result_type)<4:\n",
    "        result_type+=str(i.predict(T_set)[0])\n",
    "print(f'Model prediction: {result_type}, threshold prediction: {threshold_type}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc24e429-4432-43c6-87f1-626dcada33e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results:\n",
      "\n",
      "Your chess MBTI is UGTL (Engineer)!\n",
      "\n",
      "Here is a short description of your chess MBTI:\n",
      "You are the Engineer — precise, principled, and methodical.\n",
      "You favor clear, correct play and navigate the board like a well-designed system, valuing structure and incremental advantage. \n",
      "Your calculation is sharp, but always purposeful, and you are happy to outlast your opponent move by move. \n",
      "You thrive in openings you have mastered and positions where logic wins the day.\n",
      "\n",
      "You should definitely look up games of Anish Giri and Anatoly Karpov. Seems like you guys have a lot in common! :)\n",
      "\n",
      "Friendly advice: take up Exchange QGD/Catalan and Berlin Defense, gain some free Elo and thank me later!\n",
      "\n",
      "Being a UGTL, your competitive advantages are probably: \n",
      "1. Highly accurate and strategic in opening and middlegame transitions, often guiding the game into technical waters. \n",
      "2. Comfortable grinding out long endgames with solid positional plans. \n",
      "Cherish these traits and capitalize on them!\n",
      "\n",
      "On the other hand, be on a look out for:\n",
      "1. Can avoid creative or less-structured lines, missing chances to play dynamically. \n",
      "2. May get bogged down in dry positions, allowing active opponents counter chances.\n",
      "We can not all be flawless like Magnus. Practice and minimize your disadvantages!\n",
      "\n",
      "Main goal of Chess MBTI project is to connect chess players with opponents of MBTIs that click and make chess even more fun and enjoyable!\n",
      "So, being a UGTL, if your date happens to be a IGTV, or a UHTV - buy them a drink and friend them on lichess right away!\n"
     ]
    }
   ],
   "source": [
    "print('Test Results:\\n')\n",
    "print(f'Your chess MBTI is {result_type} ({type_dict['6'][result_type]})!\\n')\n",
    "print(f'Here is a short description of your chess MBTI:\\n{type_dict['5'][result_type]}\\n')\n",
    "print(f'You should definitely look up games of {type_dict['0'][result_type][0]} and {type_dict['0'][result_type][1]}. Seems like you guys have a lot in common! :)\\n')\n",
    "if stage in ['beginner', 'amateur']:\n",
    "    print(f'Friendly advice: take up {type_dict['1'][result_type][0][0]} and {type_dict['1'][result_type][0][1]}, gain some free Elo and thank me later!\\n')\n",
    "else:\n",
    "    print(f'Friendly advice: take up {type_dict['1'][result_type][1][0]} and {type_dict['1'][result_type][1][1]}, gain some free Elo and thank me later!\\n')\n",
    "print(f'Being a {result_type}, your competitive advantages are probably: \\n1. {type_dict['2'][result_type][0]} \\n2. {type_dict['2'][result_type][1]} \\nCherish these traits and capitalize on them!\\n')\n",
    "print(f'On the other hand, be on a look out for:\\n1. {type_dict['3'][result_type][0]} \\n2. {type_dict['3'][result_type][1]}\\nWe can not all be flawless like Magnus. Practice and minimize your disadvantages!\\n')\n",
    "print(f'Main goal of Chess MBTI project is to connect chess players with opponents of MBTIs that click and make chess even more fun and enjoyable!\\nSo, being a {result_type}, if your date happens to be a {type_dict['4'][result_type]} - buy them a drink and friend them on lichess right away!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1569a8-954c-4180-9125-5bd0a65ea1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
